{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Hebbian Learning Rule\n",
    "def hebbian_learning_rule(input_pattern, weight_matrix):\n",
    "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron Learning Rule\n",
    "def perceptron_learning_rule(input_pattern, target, weight_vector, learning_rate):\n",
    "    prediction = np.dot(weight_vector, input_pattern)\n",
    "    error = target - prediction\n",
    "    return weight_vector + learning_rate * error * input_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Delta Learning Rule\n",
    "def delta_learning_rule(input_pattern, target, weight_matrix, learning_rate):\n",
    "    prediction = np.dot(weight_matrix, input_pattern)\n",
    "    error = target - prediction\n",
    "    return weight_matrix + learning_rate * np.outer(error, input_pattern)\n",
    "\n",
    "# Correlation Learning Rule\n",
    "def correlation_learning_rule(input_pattern, weight_matrix):\n",
    "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
    "# Out Star Learning Rule\n",
    "def out_star_learning_rule(input_pattern, weight_matrix, learning_rate):\n",
    "    return weight_matrix + learning_rate * np.outer(input_pattern, input_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hebbian Weights: [[0.37596245 0.04678533 0.26230549]\n",
      " [0.79526028 0.48060893 0.91654931]\n",
      " [0.43543927 0.39664933 0.61897153]]\n",
      "\n",
      "Perceptron Weights: [0.27003434 0.54126361 0.90427   ]\n",
      "\n",
      "Delta Weights: [[0.60124633 0.29557107 0.20968621]\n",
      " [0.5013131  0.1058714  0.84597156]\n",
      " [0.61747845 0.56795612 0.80536182]]\n",
      "\n",
      "Correlation Weights: [[0.13586034 0.34368791 0.36653144]\n",
      " [0.15617941 0.44940223 0.05563218]\n",
      " [0.15389249 0.63794214 0.0293676 ]]\n",
      "\n",
      "Out Star Weights: [[0.20431891 0.97129685 0.67929083]\n",
      " [0.26783673 0.58779989 0.44700486]\n",
      " [0.11797231 0.39548443 0.90820915]]\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "# Initialize weights with random values\n",
    "hebbian_weights = np.random.rand(input_size, input_size)\n",
    "perceptron_weights = np.random.rand(input_size)\n",
    "delta_weights = np.random.rand(input_size, input_size)\n",
    "correlation_weights = np.random.rand(input_size, input_size)\n",
    "out_star_weights = np.random.rand(input_size, input_size)\n",
    "print(\"Hebbian Weights:\",hebbian_weights)\n",
    "print(\"\\nPerceptron Weights:\",perceptron_weights)\n",
    "print(\"\\nDelta Weights:\",delta_weights)\n",
    "print(\"\\nCorrelation Weights:\",correlation_weights)\n",
    "print(\"\\nOut Star Weights:\",out_star_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
